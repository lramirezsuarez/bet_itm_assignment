Resumen articulos:

Top Redis Use Cases By Core Data Structure Types
Redis es un systema de bases de datos NoSQL, no guarda datos en esquemas con tables filas y columnas, sino en estructuras de datos.
En redis se soportan los strings, listas, sets, sets organizados y hashes, tambien se soportan bitmaps, hyperlogs e indexes geospatial con sentencias de redius y streams.
- String son como los demas lenguajes, se guarda el string john en studen con 'SET "students" "john"', se obtiene el string con 'GET "student"' y se borra con 'DEL "student"'
	Casos de uso, cache de una session, queues (listas de espera), uso y medicion de cobros.
- Listas, se pueden insertar items en la cabeza o la cola de las listas, el comando LPUSH inserta en la cabeza y RPUSH inserta en la cola.
	Casos de uso, redes sociales, feeds de rsss y tablas de liderazgo.
- Sets, sirve para crear intersecciones y uniones. Se usa normalmente para realizar auditorias o ver relaciones entre multiples variables. Son rapidas, no estan organizadas pero toma el mismo tiempo agregar o remover items, no permiten llaves o valores duplicados.
	Casos de uso, Ventas de sitios ecommerce, trackeo de direcciones ip, filtrado de contenido inapropiado.
- Sets ordenados, son mucho mas rapidos, permiten la busqueda en el menor tiempo posible por su propiedad de ordenamiento.
	Casos de uso, plataformas de preguntas y respuestas, tablas de posiciones de aplicaciones o juegos, servicios de agendamiento de tareas, hashing en geolocalizacion.
- Hashes, es un mapeo entre los campos de string y los valores de un string, sirve para valores y contenedores unicos.
	Casos de uso, perfiles de usuario, posts de usuarios, almacenar metricas multiples.

Fallas graves en la seguridad de las tarjetas de credito y credenciales en Rappi
Se hizo un ejercicio de investigacion debido a muchas quejas de cobros extranos y no esperados a los usuarios de rappi, se descubrio que en el codigo que se puede ver en las paginas web de rappi, se puede tener acceso a los tokens y credenciales de acceso para kits de facebook entre otros servicios de tarjetas de credito, al no hacer una conexion segura. La solucion de estas fallas demoro 61 dias, y afecto a una gran cantidad de usuarios. Se corrigieron la mayoria de fallos, y se mejoro la seguridad de ingreso de las tarjetas de credito, pero aun hay medidas de seguridad que se podrian implementar.

10 razones para considerar multiples modelos de base de datos
1. Consolidacion, soporta multiples tipos de datos para diferentes casos de uso, y los consolida en una plataforma.
2. Escalamiento del performance, al estar separado en diferentes componentes de las consultas y los modelos se puede escalar independientemente segun los cambios que se necesiten.
3. Complejidad operacional, los diferentes componetes segun la fragmentacion de ambientes es una tarea complicada.
4. Flexibilidad, se puede mapear multiples modelos de data a un motor de almacenamiento que permita el uso de diferentes casos de uso y aplicaciones.
5. Confiabilidad, las caidas de servidores en bases de datos multiples es muy peligroso para el negocio.
6. Consistencia en los datos, un solo backend que spoporte multiples modelos de datos puede ya que el soporte de transacciones entre diferentes sistemas de bases de datos.
7. Tolerancia a los fallos, tener multilples sistemas y no uno que permite modelos multiples puede causar que cualquier fallo sea catastrofico.
8. Costo, al usarse muchas herramientas el costo se multiplica por mantenimientos, actualizaciones entre otros.
9. Transacciones, todas las transacciones se conocen en todo momento y se almacenan consistentemente.
10. Mejores aplicaciones, diferentes bases de datos es un problema operacional y que causa desarrollo demasiado pesado, Sin tanta logica innecesaria es mucho mejor debido a las bases de datos multi modelos.

De pronto normalizar no es normal
Disenos sencillos generan demasiadas tablas, y las consultas se vuelven un conjunto de inner joins para poder obtener los datos.
Esto dana el perfomance del sistema, debido a la normalizacion, que vuelve muy dificil de entender y dificil de trabajar, ademas de ser mas lento.
Solo genera diferencia con bases de datos gigantes, el perfomance no cambia mucho en tablas sencillas y un computador sencillo dara el mismo rendimiento.
Cualquier diseno de base de datos inicial que sea simple y facil de entender es lo mejor.
La gente normaliza porque los profesores les dijeron que debian hacerlo, deberias normalizar si los datos te lo dicen:
	- Si tiene sentido para el equipo.
	- Mejora el perfomance.
	- Evita muchos duplicados ademas de problemas de sincronizacion.
	- Permite escribir consultas mas sencillas.

Nunca deberias normalizar solo por un sentido de responsabilidad. No es un polvo magico para curar todos los problemas de la base de datos.
"Normaliza hasta que duela, desnormaliza hasta que funcione"

Quien necesita procedimientos almacenados de verdad?
Quien quiere realmente escribir procedimientos almacenados para cosas que se hacen con una simple consulta.
1. Los procedimientos almacenados estan escritos en bases de datos con lenguajes de mucho tiempo, con muchos errores de diseno y que lenguajes mas actuales manejan de una mejor forma.
2. No se pueden revisar en la misma interfaz de desarrollo del UI.
3. No dan mucho feedback cuando algo sale mal.
4. No pueden pasar objetos. Se llenan los queries de parametros que no dicen realmente cuando fallan donde esta el problema.
5. Los procedimientos almacenados esconden la logica de negocio.

Generalmente se dice que se usan los procedimientos para:
- Mejor perfomance por reuso de los queries.
- Se pueden asegurar individualmente en la base de datos.
- Se puede dar permiso de ejecucion de procedimientos almacenados sin dar permiso a las tablas.
- Mas facil mantenimiento.
- Un nivel de abstraccion de la base de datos.
- Pueden reducir el trafico de la red.

Para bases de datos modernas y escenarios de uso en el mundo real, los procedimientos almacenados tienen muchos fallos y muy poco beneficio practico real.
Solo deberia ser usado en las situaciones de perfomance mas critico. Se puede hacer una buena base de datos con SQL parametrizado y un solo ambiente de desarrollo coherente.

ARTICULOS SEGUNDA PARTE

El problema con el tiempo y las zonas horarias
El tiempo entre diferentes paises y zonas del mundo es diferente, variando entre horas mas o horas menos segun la zona horaria que asignamos en la base de datos, la aplicacion, etc.
Tener un caso para cada lugar es un problema, en lineas de codigo y logica.
El cambio de zonas horarias cambia mucho en todo el año, y todo va segun el pais y sus decisiones.
El mejor uso de las zonas horarias y los tiempos, es tener de referencia el numero unix que empezo a contar el tiempo a partir de 1970 y es un numero incremental entero por cada milisegundo, pero tambien existe el tiempo astrologico.
En conclusion, lo mejor es siempre usar la libreria de codigo abierto que ya se encarga de manejar el tiempo y las zonas horarias, antes de volvernos locos.
Google hizo un manejo donde todos los servidores y el tiemo se van adelantando o atrasando 1 milisegundo, durante todo un dia, de esta forma mantienen un mismo tiempo y aseguran la continuidad, que importa mas que la exactitud.

Netflix, que pasa cuando presionas reproducir?
Pensariamos que netflix funciona con servidores s3 aws que descargan el archivo y se reproduce, pero no es asi.
Mirando los datos, netflix maneja estadisticas de usuarios, concurrencia, cantidad de archivos demasiado grande.
Siendo un servicio por suscripcion los usuarios esperan que todo funcione sin problemas.
Todos los retos a los que se ha enfretado netflix a mejorado la forma del desarrollo, ya que permite acceder a la informacion de una forma facil, incluso mostrando sus progresos en charlas y articulos.
Usan AWS y open connect para entregar sus servicios.
Los servicios generales, preparacion de las aplicaciones, previews, listas de contenidos, etc viene de aws.
Al darle reproducir todo lo maneja open connect.
Netflix maneja los 3 aspectos con una integracion vertical, que permite que funcione de la mejor forma en cualquier momento.
Desde el inicio de netflix (alquilando dvds) estaban apuntando al streaming de videos online, pero lo hicieron bien al esperar el momento adecuado, en 2007 donde el internet era lo suficientemente rapido y confiable para hacer el streaming de contenidos. El tiempo en el que lo hicieron fue el momento exacto para su exito.
En sus inicios hicieron sus propios datacenters y crearon escalabilidad vertical, creando computadores llamados monolitos, donde un software hacia todo.
Una vez migraron a aws la situacion mejoro al no depender de sus propios data centers, migrando a servicios EC2 de aws en el transcurso de 8 años.
Netflix opera en 3 regiones de aws, en el caso de que una region falle, otra region toma la carga y evita que el servicio caiga.
Se hacen pruebas cada mes donde se bajan las regiones para verificar que la migracion entre regiones funcione correctamente.
Las 3 regiones que usan aseguran cobertura en todo el mundo, por la accesibilidad de las 3 regiones en la mayoria de paises.
Usando AWS ahorran dinero en comparacion con su propio datacenter.
Todo lo que no tiene que ver con el streaming del video lo maneja aws, almacenamiento escalable, logica de negocio, computacion escalada, bases de datos distribuidas escalables, procesamiento y analisis de big data, recomendaciones, etc.
Incluso las imagenes se personalizan segun la cuenta y la persona, lo que hace que netflix sea impulsado por los datos que obtiene.
Segun los datos obtenidos con otros videos que hemos visto, netflix selecciona la que mas se relaciona a nuestros gustos y asigna una imagen de portada que nos llevaria a ver alguna serie o pelicula.
Segun el dispositivo, netflix cambia el formato del video que vemos a un formato mas apropiado, de ahi se comienza un proceso donde el video recibido se valida, se divide en partes mas pequeñas y se hace el encoding de forma paralela, al final vuelve a crear un archivo por cada perfil necesario para cada dispositivo, al finalizar 1 solo video genera muchisimos archivos que incluye el video, el audio por lenguaje y los subtitulos.
Netflix maneja 3 diferentes CDN (red de distribucion de contenidos), la idea es que estos contenidos se almacenen en lugares cercanos a los usuarios.
En sus inicios netflix tenia su propio CDN, pero era muy pequeño para la cantidad de usuarios, luego tercerizo los CDNs con empresas confiables y en este tiempo pudo enfocarse a mejorar su infraestructura interna, algoritmos y programacion, finalmente creo su propio CND llamado Open Connect, mas economico, con mas calidad controlando el proceso de transmision de video, y mas escalable.
Open Connect funciona con sistemas de computacion para el almacenamiento del video, que son pequeños computadores concentrados en torres que se encargan de almacenar segun la necesidad ciertos contenidos. Al final ponen pequeños lugares de almacenamiento con el catalogo, cerca a los usuarios.
Netflix hace acuerdos con los ISP (proveedores de servicios de internet), y almacenan las unidades de Open connect en esos data centers.
Por otra parte en los puntos de intercambio de informacion (IXPs) netflix asegura la informacion en todos los lugares sin hacer su propio datacenter.
Netflix almacena continuamente los videos para poder ser accedidos desde la memoria persistente (cache), y este almacenamiento lo hace prediciendo que vamos a ver en ciertas regiones.
Se accede a netflix a traves de la red interna de los ISP y no en internet, por eso se hacen los acuerdos con las ISPs, y de esta forma las ISP no tienen que generar mas infraestructura al tratar de acceder por internet a netflix, es un gana/gana por parte de las ISP y netflix.
Los OCA (open connect appliances) se balancean segun sus cargas o sus fallos, y asi evitan que si alguno esta muy cargado o falla, la informacion no llegue o el video no se pueda transmitir.
Netflix controla los clientes que acceden a sus servicios, asi tambien manejan que todo funcione correctamente desde los 2 extremos de la conexion, todo esto por medio de sus proios SDKs (software development kits).
Finalmente el proceso cuando se preciona reproducir es:
- Seleccionamos un video para reproducir.
- Se envia un request a aws diciendo cual video queremos reproducir.
- Se verifican las licencias (los contenidos de netflix tienen licencia para cualquier parte, otros contenidos externos no, asi que segun el pais se debe verificar la licencia)
- Recibimos una url para el OCA mas apropiado a nuestra ubicacion y nuestra isp.
- Segun la calidad de la conexion se asigna un OCA.
- Segun el cliente/dispositivo se elige como recibir el contenido (encoding, formato, etc)
- El cliente se conecta al OCA y comienza a transmitir el video al dispositivo.
- Si la calidad varia se debe a la calidad de la conexion, el OCA del que recibimos, si se detecta que la calidad baja mucho se solicita un OCA diferente para recibir la informacion de video.
"Que vaina mas compleja, pero mas bien pensada y echa."

Por que Uber cambio de Postgres a MySQL.



